+++
title = "Privacy aware Deep Learning "
date_start = 2018-06-01T06:12:56-07:00

draft = false

# Tags and categories
# For example, use `tags = []` for no tags, or the form `tags = ["A Tag", "Another Tag"]` for one or more tags.
tags = ["Deep Learning", "AI Privacy"] 
categories = ["AI Security" ]

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
[image]
  # Caption (optional)
  caption = ""

  # Focal point (optional)
  # Options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight
  focal_point = ""


+++


The advent of IoT has led to massive data generation due to the widespread deployment of sensors, networks, and processing devices. Deep Learning has emerged as a popular computing paradigm that is used to process these large scale data and gather useful information. Of late, companies like Amazon and Google have provided cloud-based Deep Learning solutions. These solutions are referred to as Deep Learning as a Service (DLaaS). Recent works have demonstrated that these DLaaS systems are quite vulnerable to adversarial attacks. In this work, we explore three different adversarial scenarios i) naive adversary, ii) countermeasure-aware adversary and iii) Untrusted server. We also explore countermeasures inspired from information theory such as adding noise and data-shuffling. We quantify the impact of these countermeasures on ResNet and GoogleNet architectures using the Imagenet dataset. We demonstrate that we can outperform the adversary in all three scenarios.

